{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.read_ndjson(\"../data/output.ndjson\")\n",
    "df = df.explode(\"items\").unnest(\n",
    "    \"items\"\n",
    ")  # .filter(pl.col(\"category\").str.to_lowercase().str.contains(\"coffee\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "from typing import List\n",
    "\n",
    "import polars_ds as pds\n",
    "\n",
    "\n",
    "def longest_common_subsequence(str1, str2):\n",
    "    sequence_matcher = difflib.SequenceMatcher(None, str1, str2)\n",
    "    match = sequence_matcher.find_longest_match(0, len(str1), 0, len(str2))\n",
    "    return {\"lcs\": str1[match.a : match.a + match.size], \"start_index\": match.a}\n",
    "\n",
    "\n",
    "# Define the function to compute the similarity ratio\n",
    "def similarity_ratio(lcs, str1, str2):\n",
    "    return len(lcs) / max(min(len(str1), len(str2)), 1)\n",
    "\n",
    "\n",
    "def get_hash_map(\n",
    "    df, terms: List[str], col_name=\"description\", col_name_to_match=\"for_maarten\"\n",
    "):\n",
    "    assert col_name in df.columns, f\"The DataFrame should have a {col_name} column\"\n",
    "\n",
    "    def normalize_col(col_name: str) -> pl.Expr:\n",
    "        return (\n",
    "            pds.normalize_whitespace(\n",
    "                pds.remove_diacritics(\n",
    "                    pl.col(col_name)\n",
    "                    .str.to_lowercase()\n",
    "                    .str.strip_chars()\n",
    "                    .str.replace_all(r\"\\s+\", \" \")\n",
    "                    .str.split(\" \")\n",
    "                    .list.set_difference([\"boni\", \"bio\", \"everyday\"])\n",
    "                    .list.set_difference(pds.extract_numbers(col_name))\n",
    "                    .list.join(\" \")\n",
    "                )\n",
    "            )\n",
    "        ).alias(f\"{col_name}_normalized\")\n",
    "\n",
    "    cross_joined = df.with_columns(pl.lit(terms).alias(col_name_to_match)).explode(\n",
    "        col_name_to_match\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        cross_joined.with_columns(\n",
    "            normalize_col(col_name), normalize_col(col_name_to_match)\n",
    "        )\n",
    "        .with_columns(\n",
    "            [\n",
    "                pl.struct(f\"{col_name}_normalized\", f\"{col_name_to_match}_normalized\")\n",
    "                .map_elements(\n",
    "                    lambda x: longest_common_subsequence(\n",
    "                        x[f\"{col_name}_normalized\"],\n",
    "                        x[f\"{col_name_to_match}_normalized\"],\n",
    "                    ),\n",
    "                    return_dtype=pl.Struct({\"lcs\": pl.Utf8, \"start_index\": pl.Int64}),\n",
    "                )\n",
    "                .alias(\"lcs_struct\")\n",
    "            ]\n",
    "        )\n",
    "        .unnest(\"lcs_struct\")\n",
    "        .with_columns(pl.col(\"lcs\").str.len_chars().alias(\"lcs_len\"))\n",
    "        .with_columns(\n",
    "            pl.struct(\"lcs\", col_name, col_name_to_match)\n",
    "            .map_elements(\n",
    "                lambda row: similarity_ratio(\n",
    "                    row[\"lcs\"], row[col_name], row[col_name_to_match]\n",
    "                ),\n",
    "                return_dtype=pl.Float64,\n",
    "            )\n",
    "            .alias(\"similarity_ratio\"),\n",
    "            pl.col(\"lcs\").str.len_chars().alias(\"lcs_length\"),\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(\"similarity_ratio\")\n",
    "            .max()\n",
    "            .over(col_name)\n",
    "            .alias(\"max_similarity_ratio\")\n",
    "        )\n",
    "        .filter(pl.col(\"similarity_ratio\") == pl.col(\"max_similarity_ratio\"))\n",
    "        .filter(pl.col(\"similarity_ratio\") >= 0.9)\n",
    "        .unique(\"description\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"description\": \"GRAINDOR Bonen Espresso RFA 2.5kg\", \"price\": 7.19}, {\"description\": \"BONI BIO bananen Fairtrade +1kg\", \"price\": 2.98}]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.dumps(\n",
    "    get_hash_map(df, [\"soya\", \"espresso\", \"koffie\", \"graindor\", \"bananen\", \"actimel\"])\n",
    "    .sort(\"max_similarity_ratio\", descending=True)\n",
    "    .select(\"description\", (pl.col(\"unit_price\") * pl.col(\"amount\")).alias(\"price\"))\n",
    "    .to_dicts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th><th>page</th><th>total_amount</th><th>unit_price</th><th>unit</th><th>amount</th><th>description</th><th>category</th><th>path</th><th>for_maarten</th><th>description_prepped</th><th>score</th></tr><tr><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;2023-10-19&quot;</td><td>1</td><td>66.28</td><td>1.99</td><td>&quot;piece&quot;</td><td>1</td><td>&quot;BONI champignons groot 500g&quot;</td><td>&quot;Vegetables&quot;</td><td>&quot;data/Kasticket_19022025_17h09_…</td><td>&quot;graindor&quot;</td><td>&quot;500g champignons groot&quot;</td><td>0.4</td></tr><tr><td>&quot;2023-10-19&quot;</td><td>1</td><td>66.28</td><td>2.98</td><td>&quot;piece&quot;</td><td>1</td><td>&quot;BONI BIO bananen Fairtrade 1kg&quot;</td><td>&quot;Fruits&quot;</td><td>&quot;data/Kasticket_19022025_17h09_…</td><td>&quot;bananen&quot;</td><td>&quot;1kg fairtrade bananen&quot;</td><td>0.5</td></tr><tr><td>&quot;2023-10-19&quot;</td><td>1</td><td>66.28</td><td>7.19</td><td>&quot;piece&quot;</td><td>1</td><td>&quot;GRAINDOR Bonen Espresso RFA 2.…</td><td>&quot;Meat&quot;</td><td>&quot;data/Kasticket_19022025_17h09_…</td><td>&quot;espresso&quot;</td><td>&quot;graindor bonen espresso rfa 2.…</td><td>0.390244</td></tr><tr><td>&quot;2023-10-19&quot;</td><td>1</td><td>66.28</td><td>1.19</td><td>&quot;piece&quot;</td><td>1</td><td>&quot;mango ready to eat&quot;</td><td>&quot;Fruits&quot;</td><td>&quot;data/Kasticket_19022025_17h09_…</td><td>&quot;graindor&quot;</td><td>&quot;mango ready to eat&quot;</td><td>0.384615</td></tr><tr><td>&quot;2023-10-19&quot;</td><td>1</td><td>66.28</td><td>1.59</td><td>&quot;piece&quot;</td><td>1</td><td>&quot;BONI groene pesto 190g&quot;</td><td>&quot;cooking&quot;</td><td>&quot;data/Kasticket_19022025_17h09_…</td><td>&quot;espresso&quot;</td><td>&quot;190g groene pesto&quot;</td><td>0.4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 12)\n",
       "┌────────────┬──────┬────────────┬────────────┬───┬────────────┬────────────┬───────────┬──────────┐\n",
       "│ date       ┆ page ┆ total_amou ┆ unit_price ┆ … ┆ path       ┆ for_maarte ┆ descripti ┆ score    │\n",
       "│ ---        ┆ ---  ┆ nt         ┆ ---        ┆   ┆ ---        ┆ n          ┆ on_preppe ┆ ---      │\n",
       "│ str        ┆ i64  ┆ ---        ┆ f64        ┆   ┆ str        ┆ ---        ┆ d         ┆ f64      │\n",
       "│            ┆      ┆ f64        ┆            ┆   ┆            ┆ str        ┆ ---       ┆          │\n",
       "│            ┆      ┆            ┆            ┆   ┆            ┆            ┆ str       ┆          │\n",
       "╞════════════╪══════╪════════════╪════════════╪═══╪════════════╪════════════╪═══════════╪══════════╡\n",
       "│ 2023-10-19 ┆ 1    ┆ 66.28      ┆ 1.99       ┆ … ┆ data/Kasti ┆ graindor   ┆ 500g cham ┆ 0.4      │\n",
       "│            ┆      ┆            ┆            ┆   ┆ cket_19022 ┆            ┆ pignons   ┆          │\n",
       "│            ┆      ┆            ┆            ┆   ┆ 025_17h09_ ┆            ┆ groot     ┆          │\n",
       "│            ┆      ┆            ┆            ┆   ┆ …          ┆            ┆           ┆          │\n",
       "│ 2023-10-19 ┆ 1    ┆ 66.28      ┆ 2.98       ┆ … ┆ data/Kasti ┆ bananen    ┆ 1kg       ┆ 0.5      │\n",
       "│            ┆      ┆            ┆            ┆   ┆ cket_19022 ┆            ┆ fairtrade ┆          │\n",
       "│            ┆      ┆            ┆            ┆   ┆ 025_17h09_ ┆            ┆ bananen   ┆          │\n",
       "│            ┆      ┆            ┆            ┆   ┆ …          ┆            ┆           ┆          │\n",
       "│ 2023-10-19 ┆ 1    ┆ 66.28      ┆ 7.19       ┆ … ┆ data/Kasti ┆ espresso   ┆ graindor  ┆ 0.390244 │\n",
       "│            ┆      ┆            ┆            ┆   ┆ cket_19022 ┆            ┆ bonen     ┆          │\n",
       "│            ┆      ┆            ┆            ┆   ┆ 025_17h09_ ┆            ┆ espresso  ┆          │\n",
       "│            ┆      ┆            ┆            ┆   ┆ …          ┆            ┆ rfa 2.…   ┆          │\n",
       "│ 2023-10-19 ┆ 1    ┆ 66.28      ┆ 1.19       ┆ … ┆ data/Kasti ┆ graindor   ┆ mango     ┆ 0.384615 │\n",
       "│            ┆      ┆            ┆            ┆   ┆ cket_19022 ┆            ┆ ready to  ┆          │\n",
       "│            ┆      ┆            ┆            ┆   ┆ 025_17h09_ ┆            ┆ eat       ┆          │\n",
       "│            ┆      ┆            ┆            ┆   ┆ …          ┆            ┆           ┆          │\n",
       "│ 2023-10-19 ┆ 1    ┆ 66.28      ┆ 1.59       ┆ … ┆ data/Kasti ┆ espresso   ┆ 190g      ┆ 0.4      │\n",
       "│            ┆      ┆            ┆            ┆   ┆ cket_19022 ┆            ┆ groene    ┆          │\n",
       "│            ┆      ┆            ┆            ┆   ┆ 025_17h09_ ┆            ┆ pesto     ┆          │\n",
       "│            ┆      ┆            ┆            ┆   ┆ …          ┆            ┆           ┆          │\n",
       "└────────────┴──────┴────────────┴────────────┴───┴────────────┴────────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars_ds as pds\n",
    "\n",
    "df.with_columns(\n",
    "    pl.lit([\"soya\", \"espresso\", \"koffie\", \"graindor\", \"bananen\", \"actimel\"]).alias(\n",
    "        \"for_maarten\"\n",
    "    ),\n",
    "    pl.col(\"description\")\n",
    "    .str.to_lowercase()\n",
    "    .str.split(\" \")\n",
    "    .list.set_difference([\"boni\", \"bio\", \"everyday\"])\n",
    "    .list.set_difference(pds.extract_numbers(\"description\"))\n",
    "    .list.join(\" \")\n",
    "    .alias(\"description_prepped\"),\n",
    ").explode(\"for_maarten\").with_columns(\n",
    "    pds.str_fuzz(\n",
    "        \"description_prepped\",\n",
    "        \"for_maarten\",\n",
    "    ).alias(\"score\")\n",
    ").sort(\"score\", descending=True).filter(pl.col(\"score\") > 0.38).unique(\"description\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colli-parser-SijXCkaS-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
